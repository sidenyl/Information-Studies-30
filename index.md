## Information Studies 30

### Weekly Posts

**Week 1:**
<br/>
&emsp;
&emsp;
Packet-Switching as a key innovation that made the internet possible – breaking info into pieces, sending it over network, and pieced back together. This was how the term “end-to-end” came to be. This allowed information to be recreated if any errors occur in the line of connection. “Virtual circuit” models came about to support the resources necessary to “manage flow of data” (Gillespie 432). Alternatively, other argued for the “datagram” model that would only allow endpoints to manage data. If the endpoints aren’t reached successfully, the entire process starts over again. The advantage of this model is that the intermediate nodes are faster at the expense of retransmission time. For time sensitive tasks such as real time streaming of data, the virtual circuit model is more efficient. Otherwise, the datagram model is preferable. While the computer science programs emphasized research on datagram, the telephony companies emphasized research on virtual circuits, so the competition between the two different sectors ensued over network dominance. For the internet, the datagram model was more efficient, but the intermediate nodes still perform some routing and congestion control functions. However, as the internet began to emerge as a public and commercial network, designers are looking from more than just sending and receiving information. One of the meaning of “end-to-end” was that two networks were adjacent, but this meaning disappeared when discussing computer networks as opposed to cable networks. Another common meaning of “end-to-end” was the path taken from the start to finish within the many different path that the packet-switching design offered. Throughout the 1970s, the meaning of ETE focused on the responsibility of the endpoints to send an acknowledgement (‘ack’) of completed transaction to the sender. Into the 1980s, datagram model won over the virtual circuit model as telephone networks moved form analog switches to digital relays. Thus, the term ETE works with any network design and also works with claim about the social change thru technology. Gillespie found from his readings that the ETE “principle leads directly to the principle of simplicity in network design.” In Saltzer, Reed, and Clark paper, they change the term ETE to stand for an ideal instead of a design. Techno-futurists saw an utopian future in technology post industrial modernism. Barlow believed in end user freedom and saw threat to online speech in states and powerful corporations intent to censor the internet. Commercially, using the term ETE helps sell the products. <br/>
&emsp;
&emsp;
Understanding the internet through social/cultural aspects and “its material specifities” (Dourish). Xerox paved the way to use IP on local scale. While Appletalk required little administrative effort to set up, TCP/IP networks requires set up. More in depth analysis can happen if the “internet” wasn’t a “singular phenomenon” (Dourish). Internet has many different layer of connection making it harder to understand just which set of layer means “decentralization.” Thus, the term “othernets” helps people to understand the internet as an “internetworking space of possibilities” (Dourish). In 1984 San Francisco, Jennings wrote up a software called Fido that would allow thousands of users to exchange messages and files. Fidonet’s design had a conventional structure – daily and weekly – and an immediate structure – communication in real time; the internet takes both these structures into account.
<br/>
<br/>
**Week 2:**
<br/>
&emsp;
&emsp;
In the “As We May Think” article by Vannevar Bush, Bush looks into a future where technology amasses information in very little space. He compares technology to a spider web of metal providing cheap device with great reliability. He hypothesizes how the entire Encyclopedia Britannica could be reduced to the size of a matchbox. The introduction of the Voder machine at the World Fair displayed the conversion of text to speech. Complex arithmetic calculations can all be turned over to machines, so mathematicians are only necessary to “use symbolic logic on a high plane.” Bush coins the term “memex”; he describes it as “a device in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility.” This set up will allow selection by association, rather than by indexing. However look up of whatever the user chooses still requires indexing. </br>	
&emsp;
&emsp;
In Nelson’s Computer Lib/Dream Machines, Nelson wants to bridge the gap between laymen and “computer people” through allowing his writing to explain the working of computer without watering the complexity of the info down. He sees “Professionalism” as a “clique of insider” who does not readily provides others the rightful information everyone deserves to know. In the “Dream Machines” section of his book, Nelson discusses how the school system structures every children education in a cookie cutter fashion that does not promote children’s innate creativity. In a similar fashion, Computer Assisted Instruction (CAI) also fails to promote creative learning. People consider the teacher more “warm” and “human” whereas the computer is considered “cold” and “inhuman.” Nelson states that the computer is as “inhuman” as everyday household machines which people attribute to their warm. CAI is based off of three premises: (1) items which are short chunks and questions, (2) sequences arrangement of items, (3) dialogue which is a framework of embedded sequences. Sequenced Item Conversational systems (SIC) converse with students based of the CAI structure. The structured teaching of CAI needs extensive experimentation because of the all the many possible connection within the web and extensive debugging as a result. Additionally, the structured model of the CAI follows many of the same cookie cutter structure of the school system, dismissing creative learning. Though Nelson agrees that the “drill and practice” system helps to make correct adjustments in learning new material, a better method of learning would be for the student to control the system instead of allowing the computer system to control the student’s learning through “hyper-media.” Hyper-media includes the branching method of presentation that allows the user to act on different type of media such as words and pictures. <br/>
&emsp;
&emsp;
In Marcia Bates’s “The Design of Browsing and Berrypicking Techniques for the Online Search Interface,” she discusses the term “berrypicking” that she conveys as much more similar to how users actually search for information; using this method allows for better design of effective interfaces. “Berry-picking” differs from the traditional method of searching in the query, search process, range of search techniques, and information domain. Widely used strategies for searching include footnote chasing, journal run, area scanning, bibliographies-abstracting-indexing, and author searching. 
</br> 
</br>

**Self Portrait reflection:** 
</br>
&emsp;
&emsp;
I focused the self portrait on my interest in media: film and music. Since a large part of the introduction of new technology focused on communication, film and music represents creative communication of messages across to audiences. I began the project by using Bitable.com to create animated videos for an introduction, objective, choice, music, and movie. Using Sublime Text, I embedded the videos I made in Bitable.com into the HTML file with an iframe tag. In order to make the page more interactive, I inserted an image of a next icon that linked onto the next page. I used this process for the introduction and objective page. On the choice page, instead of a next button, I inserted a movie icon and music icon that lead to its respective page. If the user chose the movie icon, I added an additional page for movie entrance that had a next arrow to move onto the next page. For both the movie and music page, I implemented the Bitable.com video to display the choices of movie or music. Pressing the icon: one, two, or three links the user to the respective movie trailer or music on Youtube.com. Additionally, for both these pages, on the bottom right corner, I implemented a replay icon to take the user back to the choice page. To make the self portrait project easier to navigate, on the bottom of each page, I placed a navigation bar that allowed the user to switch between each page with ease. The only page that did not include a Bitable.com video on the page but included with the project’s pages was the resource page that can only be accessed through the navigation bar. I implemented this navigation bar by using a select tag that I made interactive by using Javascript function that took the user to each respective page from whichever page they clicked on. One helpful resource that helped me implement this function was a Quora discussion on the select tag. Each of these pages for the self portrait project was made with a separate HTML document. With the href value and the select tag/JS, I was able to tie the pages together for user navigation and interaction. Also, I used CSS to manipulate the background, font, font color, size, and position. 
<br/>
&emsp;
&emsp;
The reading most helpful to the self portrait project was Nelson’s article “Computer Lib/Dream Machine” from week two. Since one of the tasks of the project was to use hypertext, the article provided useful information on how to go about implementing in an interactive way. His focus on hypermedia which he describes as the “branching or performing presentations which respond to user actions, systems of prearranged words and pictures” (Nelson 313) helped me decide to focus on my interest in film and music since it connected to the growing technology. Additionally, the article helped me to try to incorporate some manner of interactivity within the project site. For example, using the icons, users can navigate between different pages of the project. In the HTML file, I implemented this through placing an “a” tag around an “image” tag. 
</br>



**Week 3:**
</br>
&emsp;
&emsp;
From pre-browser internet 1970s, tension has grown up between pipeline and frontier visions of the internet. The pipeline’s vision consists of mimicking the process of the internet from as the factories their so used to to promote cultural products. On the other hand, the frontier’s vision consists of “participation, speech, interaction, and creativity” (Lievrouw 3). Lievrouw discusses the term mediation in connection to technology in two way: (1) technology to enhance communication (2) participation in the creation and sharing of meaning. She also defines the term “new media” as technical features that mimics human behavior and the responses of users to these media. Communication scholars have separated the communication process from the devices method when Lievrouw sees technology as an integral part to communication. The idea that this media is “new” comes as a result of the “continuous interweaving of innovative activities, services, [and] systems” (7). Leivrouw and Livingstone goes on to explicitly define new media in three main components: (1) devices that enable user sharing (2) practices that user engage in (3) social organization that comes about as a result of these practices. The free access of new online information to everyone is still up to question. On receiving a message, the receiver may or may not act upon it. Media affects research has focused on what exactly conditions will allow the message to evoke action. 
<br/>
&emsp;
&emsp;
Situational International (SI) states in order to destroy the power of spectacle, people must create disruptive situations to overturn media representation of culture. Lievrouw describes detournement as collage making that derives material from cultural material. SI inspired detournement came about from May 1968 student riots in unseating Charles de Gaulle through: romantic comics with truths in speech bubbles, promotion of guerilla tactics, situationist comics, and situationists films – graffiti, posters, comics, costumes, and street theater. 
<br/>
&emsp;
&emsp;
In Wells’s “World Brain: The Idea of a Permanent World Encyclopaedia,” Wells discusses how technological access to information is not keeping up with the modern facilities such as radio, automobile, airplane, and etc. Along with the growing size of schools and universities, the lack in adequate information on technology is especially prominent. Well finds the solution in a “permanent world encyclopedia” with its microphotography and concentrated visual record. 
<br/>
&emsp;
&emsp;
In their article “Computing Ethics Values in Design,” Knobel and Bowker discuss the importance of socio technical design with values in the actual design process. Taking the socio technical design into account Facebook may have avoided the uproar of them sharing users data and the well known “Terms and Condition” agreement pages may be easier to comprehend amongst users. The benefits of GPS capability for social networking uses are overshadowed by the “backhand” of geographic privacy and lying that this technology brings about. There is also a “Matthew effect” in search engines where the most pertinent and factual information is hidden on the second page. Nissenbaum, Bowker, and Star have connected interdisciplinary experts to discuss the importance of values in design (VID). VID aims to understand values in early stages of design unlike in the past. 
</br>
**Week 4:**
<br/>
&emsp;
&emsp;
In Shanghai, advisors gather round to discuss how design could solve sociotechnical problems. They called this 2014 paper X as the unknown variable. The difference between the Radiation Oncology department and Emergency department in the healthcare field reflects the many nuances within the DesignX objective. There are nine properties that defines what exactly a DesignX problem is: design that do not account for human psychology, want for simple answer, multiple perspectives, mutually incompatible constraints, non-independence of elements, non-linear causal relations, unpredictable latencies, multiple scale sizes, dynamically changing operating characteristics. Mixing human with their social aspects makes it incredibly difficult to implement these technological systems. Traditional analyses saw human behavior as a inconvenience on the part of the human and not the machine while the designers see human behavior as a catalyst to change the machine’s design for future efficiency and productivity. Resolution can only be achieved through small, incremental steps and “muddling through” – taking whatever steps are possible at the moment (opportunistic). 
<br/>
&emsp;
&emsp;
In “The Field Guide to Human-Centered Design,” the authors discuss how all human-centered design are solvable from poverty to gender equality. They focus on inspiration, ideation, and implementation; they achieve this through interviewing, working in teams, and working with tangible prototypes. Through providing the readers with 57 methods in the guide, the authors help readers frame design challenges to get the idea into the market. Starting a design challenge means framing it first through deriving multiple solutions, filtering aspects, and writing it down. Afterwards, the designer must create a design plan through setting deadlines and dates, budgeting, meeting with team, and gradually evolving details of the project if necessary. Asking questions can only be effective if designers have done some secondary research in their particular area whether technological, behavioral, or cultural. A key to human centered design is gauging the opinion and perspective of the community designers are serving – interviewing. An example of this “interview” occurred through the loan surprise game which gauged the reaction of participants to receiving loans and changing variables based what the participation saw as attractive. One method of action the authors describe is the card sort for solar powered lights. When given a set of animal labeled cards and asked to describe which animal represented solar power, the participants chose the chicken or the cow, reflecting how they saw the solar power as great assets. 
<br/>
&emsp;
&emsp;
In “How We Became Posthuman: Virtual Bodies in Cybernetic, Literature, and Informatics,” Hayles describes posthuman as a view where “biological substrate is seen as an accident of history rather than an inevitability of life” (Hayles 2), consciousness is a minor sideshow, the body as original prothesis we can manipulate, human being can be seamlessly articulated with machines. The Hobbesian and Lockean idea that an individual owe nothing to society and holds freedom from wills of others came about by market relation in order to sell one’s labor for wages. The posthuman idea takes into account this paradox and sees no way to identify self will that is distinct from others. Gillian Brown studied the relation between humanism and anorexia as a body seen as an object to control. Posthuman follows the liberal tradition of “embodiment as the instantiation of thought/information” (Hayles 5). Hayles focuses on how information lost its body seen in Kroker’s description of “flesh-eating 90s.” 
<br/>
&emsp;
&emsp;
In the section The Case of Race Classification and Reclassification under Apartheid, Bowker and Star discusses how convoluted the race classification process was under the apartheid. Around one million South Africans were in the colored category, making up the majority of borderline cases where they, labelled colored, applied for white classification. It was made mandatory for individuals to carry around ID cards at all time. There was even a case where two preschool children were held for three years in detention to wait on the government’s decision about their race. The technology for classification were extremely crude with classification based on appearances, body structures, senseless question on lifestyle, and “pencil test.” 





### References

Dourish, P. (2015) Not The Internet, but This Internet: How Othernets Illuminate Our Feudal Internet. 5th Decennial Aarhus Conference on Critical Alternatives

Gillespie, T. (2006) Engineering a Principle: 'End-to-End' in the Design of the Internet. Social Studies of Science, Vol. 36, No. 3. Sage Publications

Bush, V. (1948). “As we may think.: The Atlantic Monthly, 101-108.

Nelson, T.H. (2003 [1974]). Excerpts from “Computer Lib/Dream Machines.” In N. Wardrip- Fruin and N. Montfort (Eds.), The New Media Reader, pp. 303-338.

Bates, M. (1989) “The Design of Browsing and Berrypicking Techniques for the Online Search Interface”

Wells, H.G. (1938). World brain: The idea of a permanent world encyclopedia. From World Brain, pp. 83-88. New York: Doubleday.

Lievrouw, L.A. (2011). Challenging the experts: Commons knowledge. In Alternative and Activist New Media, pp. 177‐213. Cambridge: Polity.

Knobel, C. Bowker, G. (2011). “Computing Ethics Values in Design: Focusing on socio-technical design with values as a critical component in the design process. Communications of the ACM.

Norman, Donald A., and Pieter Jan Stappers. (2015) "DesignX: complex sociotechnical systems." She Ji: The Journal of Design, Economics, and Innovation 1.2 83-106.

The Field Guide to Human-Centered Design

Hayles, K. (1999). “How We Became Posthuman: Virtual Bodies in Cybernetic, Literature, and Informatics” The University of Chicago Press. Read: prologue and chapter 1.

Bowker, G. C., & Star, S. L. (1999). The case of race classification and reclassification under apartheid. Sorting things out: Classification and its consequences, 195-225.

